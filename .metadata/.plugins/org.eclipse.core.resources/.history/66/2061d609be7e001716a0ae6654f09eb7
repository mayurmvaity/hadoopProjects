import java.io.IOException;

import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;


public class GrossPCatPgm {

	// Mapper class
	// For GPP Category
	
	public static class GPCatMapper extends Mapper<LongWritable, Text, Text, Text>
	{
		public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException
		{
			String []str = value.toString().split(";");
			String mykey = str[4];
			String sales = str[8];
			String cost = str[7];
			
			String myValue = cost+','+sales;
			
			context.write(new Text(mykey), new Text(myValue));
			
		}
		
	
	}
	
	// Reducer class
	
	public static class GPCatReducer extends Mapper<Text, Text, Text, DoubleWritable>
	{
		public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException
		{
			Double tcost = 0.0d;
			Double tsales = 0.0d;
			
			for(Text val : values)
			{
				String str[] = val.toString().split(",");
				
				Double cost = Double.parseDouble(str[0]);
				Double sales = Double.parseDouble(str[1]);
				
				tcost += cost;
				tsales += sales;
				
			}
			
			Double t = (tsales - tcost)/(tcost)*100;
			
			context.write(key, new DoubleWritable(t));
		}
	}
	
}
