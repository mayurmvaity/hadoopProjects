import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Partitioner;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.util.Tool;


public class C2Product extends Configured implements Tool {

	// mapper class
	public static class C2ProductM extends Mapper<LongWritable,Text,Text,Text>
	{
		public void map(LongWritable key,Text value,Context context)
		{
			try
			{
				String str[] = value.toString().split(";");
				
				String pid = str[5];
				
				context.write(new Text(pid),value);
				
			}
			catch(Exception e)
			{
				System.out.println(e.getMessage());
			}
		}
	}
	
	// partitioner class
	public static class C2ProductP extends Partitioner<Text,Text>
	{
		public int getPartition(Text key, Text value, int numReduceTasks)
		{
			String str[] = value.toString().split(";");
			char age = str[2].charAt(0);
			if(age == 'A') return 0;
			else if(age == 'B') return 1;
			else if(age == 'C') return 2;
			else if(age == 'D') return 3;
			else if(age == 'E') return 4;
			else if(age == 'F') return 5;
			else if(age == 'G') return 6;
			else if(age == 'H') return 7;
			else if(age == 'I') return 8;
			else return 9;
			
		}
	}
	
	// REDUCER CLASS
	public static class C2ProductR extends Reducer<Text,Text,Text,Text>
	{
		public int tcost = 0;
		public int tsales = 0;
		public String age = "";
		public void reduce(Text key,Iterable<Text> values,Context context)
		{
			try
			{
				
			}
			catch(Exception e)
			{
				System.out.println(e.getMessage());
			}
			
			for(Text val: values)
			{
				String str[] = val.toString().split(";");
				
				int cost = Integer.parseInt(str[7]);
				int sales = Integer.parseInt(str[8]);
				
				tcost += cost;
				tsales += sales;
				age = str[2];
				
			}
			
			if((tsales-tcost)<0)
			{
				context.write(key, new Text(age+"\t"+(tsales-tcost)));
			}
		}
	}
	
	
}
